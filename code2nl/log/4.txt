2020-08-05 15:25:08.784112: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
08/05/2020 15:25:10 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=10, config_name='', dev_filename='/content/CodeBERT/code2nl/CodeSearchNet/wiki_sql/valid.jsonl', do_eval=True, do_lower_case=False, do_test=False, do_train=True, eval_batch_size=16, eval_steps=1000, gradient_accumulation_steps=1, learning_rate=2e-05, load_model_path=None, local_rank=-1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=128, model_name_or_path='microsoft/codebert-base', model_type='roberta', no_cuda=False, num_train_epochs=3.0, output_dir='model/wiki_sql', seed=42, test_filename=None, tokenizer_name='', train_batch_size=16, train_filename='/content/CodeBERT/code2nl/CodeSearchNet/wiki_sql/train.jsonl', train_steps=50000, warmup_steps=0, weight_decay=0.0)
08/05/2020 15:25:10 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
08/05/2020 15:25:10 - INFO - filelock -   Lock 140580684996392 acquired on /root/.cache/torch/transformers/1b62771d5f5169b34713b0af1ab85d80e11f7b1812fbf3ee7d03a866c5f58e72.06eb31f0a63f4e8a136733ccac422f0abf9ffa87c3e61104b57e7075a704d008.lock
08/05/2020 15:25:10 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpa37r835q
Downloading: 100% 498/498 [00:00<00:00, 447kB/s]
08/05/2020 15:25:11 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/config.json in cache at /root/.cache/torch/transformers/1b62771d5f5169b34713b0af1ab85d80e11f7b1812fbf3ee7d03a866c5f58e72.06eb31f0a63f4e8a136733ccac422f0abf9ffa87c3e61104b57e7075a704d008
08/05/2020 15:25:11 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/1b62771d5f5169b34713b0af1ab85d80e11f7b1812fbf3ee7d03a866c5f58e72.06eb31f0a63f4e8a136733ccac422f0abf9ffa87c3e61104b57e7075a704d008
08/05/2020 15:25:11 - INFO - filelock -   Lock 140580684996392 released on /root/.cache/torch/transformers/1b62771d5f5169b34713b0af1ab85d80e11f7b1812fbf3ee7d03a866c5f58e72.06eb31f0a63f4e8a136733ccac422f0abf9ffa87c3e61104b57e7075a704d008.lock
08/05/2020 15:25:11 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/config.json from cache at /root/.cache/torch/transformers/1b62771d5f5169b34713b0af1ab85d80e11f7b1812fbf3ee7d03a866c5f58e72.06eb31f0a63f4e8a136733ccac422f0abf9ffa87c3e61104b57e7075a704d008
08/05/2020 15:25:11 - INFO - transformers.configuration_utils -   Model config RobertaConfig {
  "architectures": [
    "RobertaModel"
  ],
  "attention_probs_dropout_prob": 0.1,
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_id": 2,
  "eos_token_ids": 0,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-05,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 514,
  "model_type": "roberta",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": false,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 1,
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 1,
  "use_bfloat16": false,
  "vocab_size": 50265
}

08/05/2020 15:25:11 - INFO - transformers.tokenization_utils -   Model name 'microsoft/codebert-base' not found in model shortcut name list (roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector). Assuming 'microsoft/codebert-base' is a path, a model identifier, or url to a directory containing tokenizer files.
08/05/2020 15:25:11 - INFO - filelock -   Lock 140580684963064 acquired on /root/.cache/torch/transformers/aca4dbdf4f074d4e071c2664901fec33c8aa69c35aa0101bc669ed4b44d1f6c3.6a4061e8fc00057d21d80413635a86fdcf55b6e7594ad9e25257d2f99a02f4be.lock
08/05/2020 15:25:11 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpygmig8c1
Downloading: 100% 899k/899k [00:00<00:00, 2.08MB/s]
08/05/2020 15:25:12 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/vocab.json in cache at /root/.cache/torch/transformers/aca4dbdf4f074d4e071c2664901fec33c8aa69c35aa0101bc669ed4b44d1f6c3.6a4061e8fc00057d21d80413635a86fdcf55b6e7594ad9e25257d2f99a02f4be
08/05/2020 15:25:12 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/aca4dbdf4f074d4e071c2664901fec33c8aa69c35aa0101bc669ed4b44d1f6c3.6a4061e8fc00057d21d80413635a86fdcf55b6e7594ad9e25257d2f99a02f4be
08/05/2020 15:25:12 - INFO - filelock -   Lock 140580684963064 released on /root/.cache/torch/transformers/aca4dbdf4f074d4e071c2664901fec33c8aa69c35aa0101bc669ed4b44d1f6c3.6a4061e8fc00057d21d80413635a86fdcf55b6e7594ad9e25257d2f99a02f4be.lock
08/05/2020 15:25:12 - INFO - filelock -   Lock 140580684961664 acquired on /root/.cache/torch/transformers/779a2f0c38ba2ff65d9a3ee23e58db9568f44a20865c412365e3dc540f01743f.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock
08/05/2020 15:25:12 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp8nn52r9p
Downloading: 100% 456k/456k [00:00<00:00, 1.33MB/s]
08/05/2020 15:25:13 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/merges.txt in cache at /root/.cache/torch/transformers/779a2f0c38ba2ff65d9a3ee23e58db9568f44a20865c412365e3dc540f01743f.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
08/05/2020 15:25:13 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/779a2f0c38ba2ff65d9a3ee23e58db9568f44a20865c412365e3dc540f01743f.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
08/05/2020 15:25:13 - INFO - filelock -   Lock 140580684961664 released on /root/.cache/torch/transformers/779a2f0c38ba2ff65d9a3ee23e58db9568f44a20865c412365e3dc540f01743f.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock
08/05/2020 15:25:14 - INFO - filelock -   Lock 140580684963288 acquired on /root/.cache/torch/transformers/5a191080da4f00859b5d3d29529f57894583e00ab07b7c940d65c33db4b25d4d.16f949018cf247a2ea7465a74ca9a292212875e5fd72f969e0807011e7f192e4.lock
08/05/2020 15:25:14 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp7co177fz
Downloading: 100% 150/150 [00:00<00:00, 107kB/s]
08/05/2020 15:25:14 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/special_tokens_map.json in cache at /root/.cache/torch/transformers/5a191080da4f00859b5d3d29529f57894583e00ab07b7c940d65c33db4b25d4d.16f949018cf247a2ea7465a74ca9a292212875e5fd72f969e0807011e7f192e4
08/05/2020 15:25:14 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/5a191080da4f00859b5d3d29529f57894583e00ab07b7c940d65c33db4b25d4d.16f949018cf247a2ea7465a74ca9a292212875e5fd72f969e0807011e7f192e4
08/05/2020 15:25:14 - INFO - filelock -   Lock 140580684963288 released on /root/.cache/torch/transformers/5a191080da4f00859b5d3d29529f57894583e00ab07b7c940d65c33db4b25d4d.16f949018cf247a2ea7465a74ca9a292212875e5fd72f969e0807011e7f192e4.lock
08/05/2020 15:25:15 - INFO - filelock -   Lock 140580684963064 acquired on /root/.cache/torch/transformers/1b4723c5fb2d933e11c399450ea233aaf33f093b5cbef3ec864624735380e490.70b5dbd5d3b9b4c9bfb3d1f6464291ff52f6a8d96358899aa3834e173b45092d.lock
08/05/2020 15:25:15 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmptodn6w3r
Downloading: 100% 25.0/25.0 [00:00<00:00, 20.0kB/s]
08/05/2020 15:25:15 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/tokenizer_config.json in cache at /root/.cache/torch/transformers/1b4723c5fb2d933e11c399450ea233aaf33f093b5cbef3ec864624735380e490.70b5dbd5d3b9b4c9bfb3d1f6464291ff52f6a8d96358899aa3834e173b45092d
08/05/2020 15:25:15 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/1b4723c5fb2d933e11c399450ea233aaf33f093b5cbef3ec864624735380e490.70b5dbd5d3b9b4c9bfb3d1f6464291ff52f6a8d96358899aa3834e173b45092d
08/05/2020 15:25:15 - INFO - filelock -   Lock 140580684963064 released on /root/.cache/torch/transformers/1b4723c5fb2d933e11c399450ea233aaf33f093b5cbef3ec864624735380e490.70b5dbd5d3b9b4c9bfb3d1f6464291ff52f6a8d96358899aa3834e173b45092d.lock
08/05/2020 15:25:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/vocab.json from cache at /root/.cache/torch/transformers/aca4dbdf4f074d4e071c2664901fec33c8aa69c35aa0101bc669ed4b44d1f6c3.6a4061e8fc00057d21d80413635a86fdcf55b6e7594ad9e25257d2f99a02f4be
08/05/2020 15:25:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/merges.txt from cache at /root/.cache/torch/transformers/779a2f0c38ba2ff65d9a3ee23e58db9568f44a20865c412365e3dc540f01743f.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda
08/05/2020 15:25:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/added_tokens.json from cache at None
08/05/2020 15:25:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/special_tokens_map.json from cache at /root/.cache/torch/transformers/5a191080da4f00859b5d3d29529f57894583e00ab07b7c940d65c33db4b25d4d.16f949018cf247a2ea7465a74ca9a292212875e5fd72f969e0807011e7f192e4
08/05/2020 15:25:15 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/tokenizer_config.json from cache at /root/.cache/torch/transformers/1b4723c5fb2d933e11c399450ea233aaf33f093b5cbef3ec864624735380e490.70b5dbd5d3b9b4c9bfb3d1f6464291ff52f6a8d96358899aa3834e173b45092d
08/05/2020 15:25:16 - INFO - filelock -   Lock 140580684993480 acquired on /root/.cache/torch/transformers/3416309b564f60f87c1bc2ce8d8a82bb7c1e825b241c816482f750b48a5cdc26.96251fe4478bac0cff9de8ae3201e5847cee59aebbcafdfe6b2c361f9398b349.lock
08/05/2020 15:25:16 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpjl9o9kp9
Downloading: 100% 499M/499M [01:03<00:00, 7.84MB/s]
08/05/2020 15:26:20 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/pytorch_model.bin in cache at /root/.cache/torch/transformers/3416309b564f60f87c1bc2ce8d8a82bb7c1e825b241c816482f750b48a5cdc26.96251fe4478bac0cff9de8ae3201e5847cee59aebbcafdfe6b2c361f9398b349
08/05/2020 15:26:20 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/3416309b564f60f87c1bc2ce8d8a82bb7c1e825b241c816482f750b48a5cdc26.96251fe4478bac0cff9de8ae3201e5847cee59aebbcafdfe6b2c361f9398b349
08/05/2020 15:26:20 - INFO - filelock -   Lock 140580684993480 released on /root/.cache/torch/transformers/3416309b564f60f87c1bc2ce8d8a82bb7c1e825b241c816482f750b48a5cdc26.96251fe4478bac0cff9de8ae3201e5847cee59aebbcafdfe6b2c361f9398b349.lock
08/05/2020 15:26:20 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/microsoft/codebert-base/pytorch_model.bin from cache at /root/.cache/torch/transformers/3416309b564f60f87c1bc2ce8d8a82bb7c1e825b241c816482f750b48a5cdc26.96251fe4478bac0cff9de8ae3201e5847cee59aebbcafdfe6b2c361f9398b349
08/05/2020 15:26:38 - INFO - __main__ -   *** Example ***
08/05/2020 15:26:38 - INFO - __main__ -   idx: 0
08/05/2020 15:26:38 - INFO - __main__ -   source_tokens: ['<s>', 'What', '_is', '_every', '_number', '_when', '_the', '_player', '_is', '_A', 'ig', 'ars', '_Vit', 'ols', '?', '</s>']
08/05/2020 15:26:38 - INFO - __main__ -   source_ids: 0 2264 16 358 346 77 5 869 16 83 1023 2726 24589 11925 116 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/05/2020 15:26:38 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
08/05/2020 15:26:38 - INFO - __main__ -   target_tokens: ['<s>', 'SELECT', '_No', '_FROM', '_table', '_', '1', '_', '23', '67', '00', '57', '_', '7', '_WHERE', '_Player', '_=', '_A', 'ig', 'ars', '_Vit', 'ols', '</s>']
08/05/2020 15:26:38 - INFO - __main__ -   target_ids: 0 49179 440 11974 2103 1215 134 1215 1922 4111 612 4390 1215 406 29919 8251 5457 83 1023 2726 24589 11925 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/05/2020 15:26:38 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
08/05/2020 15:26:38 - INFO - __main__ -   *** Example ***
08/05/2020 15:26:38 - INFO - __main__ -   idx: 1
08/05/2020 15:26:38 - INFO - __main__ -   source_tokens: ['<s>', 'What', '_is', '_the', '_River', '_Mile', '_with', '_a', '_R', 'DB', '_lock', '_side', '_and', '_a', '_pool', '_length', '_of', '_55', '_.', '_4', '?', '</s>']
08/05/2020 15:26:38 - INFO - __main__ -   source_ids: 0 2264 16 5 1995 14640 19 10 248 10842 7014 526 8 10 3716 5933 9 3490 479 204 116 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/05/2020 15:26:38 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
08/05/2020 15:26:38 - INFO - __main__ -   target_tokens: ['<s>', 'SELECT', '_River', '_Mile', '_FROM', '_table', '_', '2', '_', '18', '62', '12', '04', '_', '2', '_WHERE', '_Lock', '_Side', '_=', '_r', 'db', '_AND', '_Pool', '_Length', '_(', '_miles', '_)', '_=', '_55', '_.', '_4', '</s>']
08/05/2020 15:26:38 - INFO - __main__ -   target_ids: 0 49179 1995 14640 11974 2103 1215 176 1215 1366 5379 1092 3387 1215 176 29919 11647 9120 5457 910 33845 4248 13906 41852 36 1788 4839 5457 3490 479 204 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/05/2020 15:26:38 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
08/05/2020 15:26:38 - INFO - __main__ -   *** Example ***
08/05/2020 15:26:38 - INFO - __main__ -   idx: 2
08/05/2020 15:26:38 - INFO - __main__ -   source_tokens: ['<s>', 'What', '_s', '_the', '_Loss', '_for', '_the', '_game', '_that', '_had', '_a', '_22', '_-', '_24', '_record', '?', '</s>']
08/05/2020 15:26:38 - INFO - __main__ -   source_ids: 0 2264 579 5 19700 13 5 177 14 56 10 820 111 706 638 116 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/05/2020 15:26:38 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
08/05/2020 15:26:38 - INFO - __main__ -   target_tokens: ['<s>', 'SELECT', '_Loss', '_FROM', '_table', '_', '2', '_', '14', '26', '95', '40', '_', '5', '_WHERE', '_Record', '_=', '_22', '_-', '_24', '</s>']
08/05/2020 15:26:38 - INFO - __main__ -   target_ids: 0 49179 19700 11974 2103 1215 176 1215 1570 2481 4015 1749 1215 245 29919 10788 5457 820 111 706 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/05/2020 15:26:38 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
08/05/2020 15:26:38 - INFO - __main__ -   *** Example ***
08/05/2020 15:26:38 - INFO - __main__ -   idx: 3
08/05/2020 15:26:38 - INFO - __main__ -   source_tokens: ['<s>', 'What', '_is', '_D', '3', '車', '?', '_D', '3', '車', '?', '_[', '_', '谷', '?', '那', '﹞', '_]', '_when', '_', '辰', '?', '_', '辰', '?', '_[', '_', '那', '?', '_/', '_', '谷', '㏒', '_]', '_is', '_', '辰', '?', '_', '辰', '?', '_[', '_t', '赤', '?', '那', '?', '那', '?', '_]', '_?', '</s>']
08/05/2020 15:26:38 - INFO - __main__ -   source_ids: 0 2264 16 18697 15264 49013 27 18697 15264 49013 27 646 1437 35423 5543 38155 18400 27779 77 1437 48561 15722 1437 48561 15722 646 1437 38155 10172 1589 1437 35423 2469 27779 16 1437 48561 9470 1437 48561 9470 646 326 48254 5543 38155 9264 38155 4394 27779 17487 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/05/2020 15:26:38 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
08/05/2020 15:26:38 - INFO - __main__ -   target_tokens: ['<s>', 'SELECT', '_D', '?', '車', '?', '_D', '3', '車', '?', '_[', '_', '谷', '?', '那', '﹞', '_]', '_FROM', '_table', '_', '1', '_', '20', '23', '65', '_', '2', '_WHERE', '_', '辰', '?', '_', '辰', '?', '_[', '_', '那', '?', '_/', '_', '谷', '㏒', '_]', '_=', '_', '辰', '?', '_', '辰', '?', '_[', '_t', '赤', '?', '那', '?', '那', '?', '_]', '</s>']
08/05/2020 15:26:38 - INFO - __main__ -   target_ids: 0 49179 18697 9085 49013 27 18697 15264 49013 27 646 1437 35423 5543 38155 18400 27779 11974 2103 1215 134 1215 844 1922 3506 1215 176 29919 1437 48561 10674 1437 48561 15722 646 1437 38155 10172 1589 1437 35423 2469 27779 5457 1437 48561 4726 1437 48561 9470 646 326 48254 5543 38155 9264 38155 4394 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/05/2020 15:26:38 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
08/05/2020 15:26:38 - INFO - __main__ -   *** Example ***
08/05/2020 15:26:38 - INFO - __main__ -   idx: 4
08/05/2020 15:26:38 - INFO - __main__ -   source_tokens: ['<s>', 'When', '_22', '_is', '_the', '_number', '_what', '_is', '_the', '_episode', '_title', '?', '</s>']
08/05/2020 15:26:38 - INFO - __main__ -   source_ids: 0 1779 820 16 5 346 99 16 5 3238 1270 116 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/05/2020 15:26:38 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
08/05/2020 15:26:38 - INFO - __main__ -   target_tokens: ['<s>', 'SELECT', '_Episode', '_title', '_FROM', '_table', '_', '1', '_', '294', '75', '589', '_', '3', '_WHERE', '_No', '_.', '_=', '_22', '</s>']
08/05/2020 15:26:38 - INFO - __main__ -   target_ids: 0 49179 16012 1270 11974 2103 1215 134 1215 32004 2545 40017 1215 246 29919 440 479 5457 820 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
08/05/2020 15:26:38 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
08/05/2020 15:26:53 - INFO - __main__ -   ***** Running training *****
08/05/2020 15:26:53 - INFO - __main__ -     Num examples = 54208
08/05/2020 15:26:53 - INFO - __main__ -     Batch size = 16
08/05/2020 15:26:53 - INFO - __main__ -     Num epoch = 14
loss 12.7294:   0% 0/50000 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)
  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)
loss 3.4033:   2% 998/50000 [18:38<15:31:18,  1.14s/it]08/05/2020 15:45:34 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 15:45:34 - INFO - __main__ -     Num examples = 5946
08/05/2020 15:45:34 - INFO - __main__ -     Batch size = 16
08/05/2020 15:47:59 - INFO - __main__ -     eval_ppl = 12.6044
08/05/2020 15:47:59 - INFO - __main__ -     global_step = 1000
08/05/2020 15:47:59 - INFO - __main__ -     train_loss = 3.4033
08/05/2020 15:47:59 - INFO - __main__ -     ********************
08/05/2020 15:48:01 - INFO - __main__ -     Best ppl:12.6044
08/05/2020 15:48:01 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 15:59:13 - INFO - __main__ -     bleu-4 = 38.07 
08/05/2020 15:59:13 - INFO - __main__ -     ********************
08/05/2020 15:59:13 - INFO - __main__ -     Best bleu:38.07
08/05/2020 15:59:13 - INFO - __main__ -     ********************
loss 2.3022:   4% 1998/50000 [51:23<15:12:01,  1.14s/it]08/05/2020 16:18:17 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 16:18:17 - INFO - __main__ -     Num examples = 5946
08/05/2020 16:18:17 - INFO - __main__ -     Batch size = 16
08/05/2020 16:20:42 - INFO - __main__ -     eval_ppl = 6.85915
08/05/2020 16:20:42 - INFO - __main__ -     global_step = 2000
08/05/2020 16:20:42 - INFO - __main__ -     train_loss = 2.3022
08/05/2020 16:20:42 - INFO - __main__ -     ********************
08/05/2020 16:20:44 - INFO - __main__ -     Best ppl:6.85915
08/05/2020 16:20:44 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 16:32:43 - INFO - __main__ -     bleu-4 = 42.1 
08/05/2020 16:32:43 - INFO - __main__ -     ********************
08/05/2020 16:32:43 - INFO - __main__ -     Best bleu:42.1
08/05/2020 16:32:43 - INFO - __main__ -     ********************
loss 1.8722:   6% 2998/50000 [1:24:52<14:55:48,  1.14s/it]08/05/2020 16:51:46 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 16:51:46 - INFO - __main__ -     Num examples = 5946
08/05/2020 16:51:46 - INFO - __main__ -     Batch size = 16
08/05/2020 16:54:11 - INFO - __main__ -     eval_ppl = 4.97076
08/05/2020 16:54:11 - INFO - __main__ -     global_step = 3000
08/05/2020 16:54:11 - INFO - __main__ -     train_loss = 1.8722
08/05/2020 16:54:11 - INFO - __main__ -     ********************
08/05/2020 16:54:14 - INFO - __main__ -     Best ppl:4.97076
08/05/2020 16:54:14 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 17:05:27 - INFO - __main__ -     bleu-4 = 46.53 
08/05/2020 17:05:27 - INFO - __main__ -     ********************
08/05/2020 17:05:27 - INFO - __main__ -     Best bleu:46.53
08/05/2020 17:05:27 - INFO - __main__ -     ********************
loss 1.5945:   8% 3998/50000 [1:57:36<14:36:58,  1.14s/it]08/05/2020 17:24:30 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 17:24:30 - INFO - __main__ -     Num examples = 5946
08/05/2020 17:24:30 - INFO - __main__ -     Batch size = 16
08/05/2020 17:26:55 - INFO - __main__ -     eval_ppl = 4.12914
08/05/2020 17:26:55 - INFO - __main__ -     global_step = 4000
08/05/2020 17:26:55 - INFO - __main__ -     train_loss = 1.5945
08/05/2020 17:26:55 - INFO - __main__ -     ********************
08/05/2020 17:26:58 - INFO - __main__ -     Best ppl:4.12914
08/05/2020 17:26:58 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 17:38:15 - INFO - __main__ -     bleu-4 = 49.79 
08/05/2020 17:38:15 - INFO - __main__ -     ********************
08/05/2020 17:38:15 - INFO - __main__ -     Best bleu:49.79
08/05/2020 17:38:15 - INFO - __main__ -     ********************
loss 1.4194:  10% 4998/50000 [2:30:25<14:17:10,  1.14s/it]08/05/2020 17:57:19 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 17:57:19 - INFO - __main__ -     Num examples = 5946
08/05/2020 17:57:19 - INFO - __main__ -     Batch size = 16
08/05/2020 17:59:44 - INFO - __main__ -     eval_ppl = 3.78559
08/05/2020 17:59:44 - INFO - __main__ -     global_step = 5000
08/05/2020 17:59:44 - INFO - __main__ -     train_loss = 1.4194
08/05/2020 17:59:44 - INFO - __main__ -     ********************
08/05/2020 17:59:47 - INFO - __main__ -     Best ppl:3.78559
08/05/2020 17:59:47 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 18:11:12 - INFO - __main__ -     bleu-4 = 54.36 
08/05/2020 18:11:12 - INFO - __main__ -     ********************
08/05/2020 18:11:12 - INFO - __main__ -     Best bleu:54.36
08/05/2020 18:11:12 - INFO - __main__ -     ********************
loss 1.3133:  12% 5998/50000 [3:03:23<13:56:31,  1.14s/it]08/05/2020 18:30:17 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 18:30:17 - INFO - __main__ -     Num examples = 5946
08/05/2020 18:30:17 - INFO - __main__ -     Batch size = 16
08/05/2020 18:32:41 - INFO - __main__ -     eval_ppl = 3.55019
08/05/2020 18:32:41 - INFO - __main__ -     global_step = 6000
08/05/2020 18:32:41 - INFO - __main__ -     train_loss = 1.3133
08/05/2020 18:32:41 - INFO - __main__ -     ********************
08/05/2020 18:32:44 - INFO - __main__ -     Best ppl:3.55019
08/05/2020 18:32:44 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 18:44:24 - INFO - __main__ -     bleu-4 = 54.66 
08/05/2020 18:44:24 - INFO - __main__ -     ********************
08/05/2020 18:44:24 - INFO - __main__ -     Best bleu:54.66
08/05/2020 18:44:24 - INFO - __main__ -     ********************
loss 1.2445:  14% 6998/50000 [3:36:34<13:42:14,  1.15s/it]08/05/2020 19:03:28 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 19:03:28 - INFO - __main__ -     Num examples = 5946
08/05/2020 19:03:28 - INFO - __main__ -     Batch size = 16
08/05/2020 19:05:53 - INFO - __main__ -     eval_ppl = 3.40535
08/05/2020 19:05:53 - INFO - __main__ -     global_step = 7000
08/05/2020 19:05:53 - INFO - __main__ -     train_loss = 1.2445
08/05/2020 19:05:53 - INFO - __main__ -     ********************
08/05/2020 19:05:55 - INFO - __main__ -     Best ppl:3.40535
08/05/2020 19:05:55 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 19:17:22 - INFO - __main__ -     bleu-4 = 55.96 
08/05/2020 19:17:22 - INFO - __main__ -     ********************
08/05/2020 19:17:22 - INFO - __main__ -     Best bleu:55.96
08/05/2020 19:17:22 - INFO - __main__ -     ********************
loss 1.178:  16% 7998/50000 [4:09:30<13:18:44,  1.14s/it] 08/05/2020 19:36:23 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 19:36:23 - INFO - __main__ -     Num examples = 5946
08/05/2020 19:36:23 - INFO - __main__ -     Batch size = 16
08/05/2020 19:38:48 - INFO - __main__ -     eval_ppl = 3.28173
08/05/2020 19:38:48 - INFO - __main__ -     global_step = 8000
08/05/2020 19:38:48 - INFO - __main__ -     train_loss = 1.178
08/05/2020 19:38:48 - INFO - __main__ -     ********************
08/05/2020 19:38:50 - INFO - __main__ -     Best ppl:3.28173
08/05/2020 19:38:50 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 19:50:08 - INFO - __main__ -     bleu-4 = 58.43 
08/05/2020 19:50:08 - INFO - __main__ -     ********************
08/05/2020 19:50:08 - INFO - __main__ -     Best bleu:58.43
08/05/2020 19:50:08 - INFO - __main__ -     ********************
loss 1.1155:  18% 8998/50000 [4:42:16<12:58:37,  1.14s/it]08/05/2020 20:09:10 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 20:09:10 - INFO - __main__ -     Num examples = 5946
08/05/2020 20:09:10 - INFO - __main__ -     Batch size = 16
08/05/2020 20:11:35 - INFO - __main__ -     eval_ppl = 3.19484
08/05/2020 20:11:35 - INFO - __main__ -     global_step = 9000
08/05/2020 20:11:35 - INFO - __main__ -     train_loss = 1.1155
08/05/2020 20:11:35 - INFO - __main__ -     ********************
08/05/2020 20:11:37 - INFO - __main__ -     Best ppl:3.19484
08/05/2020 20:11:37 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 20:22:45 - INFO - __main__ -     bleu-4 = 57.52 
08/05/2020 20:22:45 - INFO - __main__ -     ********************
loss 1.0846:  20% 9998/50000 [5:14:49<12:39:25,  1.14s/it]08/05/2020 20:41:43 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 20:41:43 - INFO - __main__ -     Num examples = 5946
08/05/2020 20:41:43 - INFO - __main__ -     Batch size = 16
08/05/2020 20:44:08 - INFO - __main__ -     eval_ppl = 3.12523
08/05/2020 20:44:08 - INFO - __main__ -     global_step = 10000
08/05/2020 20:44:08 - INFO - __main__ -     train_loss = 1.0846
08/05/2020 20:44:08 - INFO - __main__ -     ********************
08/05/2020 20:44:10 - INFO - __main__ -     Best ppl:3.12523
08/05/2020 20:44:10 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 20:55:13 - INFO - __main__ -     bleu-4 = 59.41 
08/05/2020 20:55:13 - INFO - __main__ -     ********************
08/05/2020 20:55:13 - INFO - __main__ -     Best bleu:59.41
08/05/2020 20:55:13 - INFO - __main__ -     ********************
loss 1.0481:  22% 10998/50000 [5:47:19<12:21:46,  1.14s/it]08/05/2020 21:14:13 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 21:14:13 - INFO - __main__ -     Num examples = 5946
08/05/2020 21:14:13 - INFO - __main__ -     Batch size = 16
08/05/2020 21:16:38 - INFO - __main__ -     eval_ppl = 3.0596
08/05/2020 21:16:38 - INFO - __main__ -     global_step = 11000
08/05/2020 21:16:38 - INFO - __main__ -     train_loss = 1.0481
08/05/2020 21:16:38 - INFO - __main__ -     ********************
08/05/2020 21:16:40 - INFO - __main__ -     Best ppl:3.0596
08/05/2020 21:16:40 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 21:27:55 - INFO - __main__ -     bleu-4 = 59.07 
08/05/2020 21:27:55 - INFO - __main__ -     ********************
loss 0.9972:  24% 11998/50000 [6:19:58<12:03:50,  1.14s/it]08/05/2020 21:46:52 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 21:46:52 - INFO - __main__ -     Num examples = 5946
08/05/2020 21:46:52 - INFO - __main__ -     Batch size = 16
08/05/2020 21:49:17 - INFO - __main__ -     eval_ppl = 3.01382
08/05/2020 21:49:17 - INFO - __main__ -     global_step = 12000
08/05/2020 21:49:17 - INFO - __main__ -     train_loss = 0.9972
08/05/2020 21:49:17 - INFO - __main__ -     ********************
08/05/2020 21:49:19 - INFO - __main__ -     Best ppl:3.01382
08/05/2020 21:49:19 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 22:00:29 - INFO - __main__ -     bleu-4 = 60.15 
08/05/2020 22:00:29 - INFO - __main__ -     ********************
08/05/2020 22:00:29 - INFO - __main__ -     Best bleu:60.15
08/05/2020 22:00:29 - INFO - __main__ -     ********************
loss 0.976:  26% 12998/50000 [6:52:37<11:42:19,  1.14s/it]08/05/2020 22:19:30 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 22:19:30 - INFO - __main__ -     Num examples = 5946
08/05/2020 22:19:30 - INFO - __main__ -     Batch size = 16
08/05/2020 22:21:55 - INFO - __main__ -     eval_ppl = 2.98053
08/05/2020 22:21:55 - INFO - __main__ -     global_step = 13000
08/05/2020 22:21:55 - INFO - __main__ -     train_loss = 0.976
08/05/2020 22:21:55 - INFO - __main__ -     ********************
08/05/2020 22:21:57 - INFO - __main__ -     Best ppl:2.98053
08/05/2020 22:21:57 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 22:33:01 - INFO - __main__ -     bleu-4 = 60.61 
08/05/2020 22:33:01 - INFO - __main__ -     ********************
08/05/2020 22:33:01 - INFO - __main__ -     Best bleu:60.61
08/05/2020 22:33:01 - INFO - __main__ -     ********************
loss 0.9535:  28% 13998/50000 [7:25:09<11:24:02,  1.14s/it]08/05/2020 22:52:03 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 22:52:03 - INFO - __main__ -     Num examples = 5946
08/05/2020 22:52:03 - INFO - __main__ -     Batch size = 16
08/05/2020 22:54:28 - INFO - __main__ -     eval_ppl = 2.93506
08/05/2020 22:54:28 - INFO - __main__ -     global_step = 14000
08/05/2020 22:54:28 - INFO - __main__ -     train_loss = 0.9535
08/05/2020 22:54:28 - INFO - __main__ -     ********************
08/05/2020 22:54:30 - INFO - __main__ -     Best ppl:2.93506
08/05/2020 22:54:30 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 23:05:34 - INFO - __main__ -     bleu-4 = 59.46 
08/05/2020 23:05:34 - INFO - __main__ -     ********************
loss 0.9156:  30% 14998/50000 [7:57:40<11:05:26,  1.14s/it]08/05/2020 23:24:34 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 23:24:34 - INFO - __main__ -     Num examples = 5946
08/05/2020 23:24:34 - INFO - __main__ -     Batch size = 16
08/05/2020 23:26:59 - INFO - __main__ -     eval_ppl = 2.91408
08/05/2020 23:26:59 - INFO - __main__ -     global_step = 15000
08/05/2020 23:26:59 - INFO - __main__ -     train_loss = 0.9156
08/05/2020 23:26:59 - INFO - __main__ -     ********************
08/05/2020 23:27:02 - INFO - __main__ -     Best ppl:2.91408
08/05/2020 23:27:02 - INFO - __main__ -     ********************
Total: 1000
08/05/2020 23:38:15 - INFO - __main__ -     bleu-4 = 61.7 
08/05/2020 23:38:15 - INFO - __main__ -     ********************
08/05/2020 23:38:15 - INFO - __main__ -     Best bleu:61.7
08/05/2020 23:38:15 - INFO - __main__ -     ********************
loss 0.8892:  32% 15998/50000 [8:30:25<10:48:01,  1.14s/it]08/05/2020 23:57:18 - INFO - __main__ -   
***** Running evaluation *****
08/05/2020 23:57:18 - INFO - __main__ -     Num examples = 5946
08/05/2020 23:57:18 - INFO - __main__ -     Batch size = 16
08/05/2020 23:59:44 - INFO - __main__ -     eval_ppl = 2.94266
08/05/2020 23:59:44 - INFO - __main__ -     global_step = 16000
08/05/2020 23:59:44 - INFO - __main__ -     train_loss = 0.8892
08/05/2020 23:59:44 - INFO - __main__ -     ********************
Total: 1000
08/06/2020 00:10:56 - INFO - __main__ -     bleu-4 = 60.84 
08/06/2020 00:10:56 - INFO - __main__ -     ********************
loss 0.8767:  34% 16998/50000 [9:03:01<10:25:32,  1.14s/it]08/06/2020 00:29:55 - INFO - __main__ -   
***** Running evaluation *****
08/06/2020 00:29:55 - INFO - __main__ -     Num examples = 5946
08/06/2020 00:29:55 - INFO - __main__ -     Batch size = 16
08/06/2020 00:32:19 - INFO - __main__ -     eval_ppl = 2.86345
08/06/2020 00:32:19 - INFO - __main__ -     global_step = 17000
08/06/2020 00:32:19 - INFO - __main__ -     train_loss = 0.8767
08/06/2020 00:32:19 - INFO - __main__ -     ********************
08/06/2020 00:32:21 - INFO - __main__ -     Best ppl:2.86345
08/06/2020 00:32:21 - INFO - __main__ -     ********************
Total: 1000
08/06/2020 00:43:44 - INFO - __main__ -     bleu-4 = 61.9 
08/06/2020 00:43:44 - INFO - __main__ -     ********************
08/06/2020 00:43:44 - INFO - __main__ -     Best bleu:61.9
08/06/2020 00:43:44 - INFO - __main__ -     ********************
loss 0.8512:  36% 17998/50000 [9:35:54<10:06:35,  1.14s/it]08/06/2020 01:02:48 - INFO - __main__ -   
***** Running evaluation *****
08/06/2020 01:02:48 - INFO - __main__ -     Num examples = 5946
08/06/2020 01:02:48 - INFO - __main__ -     Batch size = 16
08/06/2020 01:05:12 - INFO - __main__ -     eval_ppl = 2.85027
08/06/2020 01:05:12 - INFO - __main__ -     global_step = 18000
08/06/2020 01:05:12 - INFO - __main__ -     train_loss = 0.8512
08/06/2020 01:05:12 - INFO - __main__ -     ********************
08/06/2020 01:05:15 - INFO - __main__ -     Best ppl:2.85027
08/06/2020 01:05:15 - INFO - __main__ -     ********************
Total: 1000
08/06/2020 01:16:33 - INFO - __main__ -     bleu-4 = 62.12 
08/06/2020 01:16:33 - INFO - __main__ -     ********************
08/06/2020 01:16:33 - INFO - __main__ -     Best bleu:62.12
08/06/2020 01:16:33 - INFO - __main__ -     ********************